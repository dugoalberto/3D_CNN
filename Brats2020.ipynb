{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"0101417913c04c2ab22688d7c4cc2244":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0330276edd984881a7942433f07ff6c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06452cd57d0d46fcb0b7b4b620af7431":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"09b750b30cc045c5aad3ee232eaf4c3e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09b97dff024043c9befcc4ddb7711036":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb417705b6784c8fb000d91d69475e49","IPY_MODEL_25868ac8afca4475887caf47154d5907","IPY_MODEL_d957df81de0c4688a963ae08d186ebfa"],"layout":"IPY_MODEL_5c3fd6a52cfc47cb8f98a2893dc8521c"}},"0dee265f717747349ab4d59d4dfb5012":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0330276edd984881a7942433f07ff6c6","max":206994458,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bb35836e1b7346e8b6c4bb4f32c7d714","value":206994458}},"0e13f9cad0c147f49b40d38d1817dd54":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f53d5569aec4ad28c2bdab743cc51e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1485ba524e2d48cc95f0872593022113":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"17bf6e890bd84eecb79d64ac39e71485":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1fcb968068e54d719e9ebb9ca8a46f69":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2447c1f91098423fb1171cb67a8029d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25868ac8afca4475887caf47154d5907":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_09b750b30cc045c5aad3ee232eaf4c3e","max":206994234,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3f8b5da6d2a54b0fab09039d807f3056","value":206994234}},"29332ea751b746a98098a4782ab837ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30a5ebdb8d5b4d0fab4c6a27010a94af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9750f4173efd4e878abbd32ac697a13b","placeholder":"​","style":"IPY_MODEL_3937ec9dbb7a46b6a5bc5fd4fea7d94b","value":"BratsCV_epoch_30.pt:  86%"}},"30cb54e6e8d14532aa544cd5227f0900":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31150334d6f94bdc861f2cbc2140083a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"334ac583728545e4bb53c5907b03cab2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_552269a2e190488b8c5ccbd111b27d2e","max":184608718,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a6f5587506574aebb064896706609a9c","value":184608718}},"35be443e8c3a4ea1a3211ee25da8f669":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e0c787d4ca664b25a13b6bd06322aa4b","IPY_MODEL_8038ac8f6df742868be37cdfce377620","IPY_MODEL_e4fd195805604064950f941d03b9c50a"],"layout":"IPY_MODEL_7751f31624d34e45b7656f4ecad497ba"}},"379cf7850a6d4b2c8a7b2b7f9e25295e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3937ec9dbb7a46b6a5bc5fd4fea7d94b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39f6ea6f3d604ad195a7abf96142a672":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a064552196245daa2dce23ce3f17e89":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a85e48858b04398bd73c770f2cd79ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b316a62934844a6dac2d14796ae781f4","placeholder":"​","style":"IPY_MODEL_79940d98186349e7b1a2b6164c059c82","value":" 207M/207M [00:08&lt;00:00, 23.0MB/s]"}},"3b8d6460771547d397adabb40db58016":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39f6ea6f3d604ad195a7abf96142a672","placeholder":"​","style":"IPY_MODEL_7142cbf7d6f84abe94dc9467a2e20aee","value":"BratsCV_best.pt: 100%"}},"3f245fdd02064c94b19f923e921080c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f8b5da6d2a54b0fab09039d807f3056":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"423134a8c93d44bfa19a10b16aac7078":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_959fc1624d3f4bb5bbddde7fd4385b02","placeholder":"​","style":"IPY_MODEL_6dccbda6c7ac44778efdbac98b3e11c7","value":" 207M/207M [00:09&lt;00:00, 23.1MB/s]"}},"423ea92d3f764b31b5cc9517a0b34494":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44cfc4db605f4b31882ba634719cf445":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4579438d457d4ae298fceef22c4f215e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46b3e77478514273b87f91cd2e7acda6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e8aaac2b86034c29a52ed5f6c2071d13","IPY_MODEL_c5fe4eeb165143fcbd692c7ca621b1e3","IPY_MODEL_423134a8c93d44bfa19a10b16aac7078"],"layout":"IPY_MODEL_ac678d71eafb41749553bccca9839954"}},"48a92b6ea58148eea8beac5634e68697":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d33e2acac44408bbaec22cd12087d4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c547671ecdee43538c4e0b125169a84f","IPY_MODEL_ee904822cfb4460db7725590b50992b9","IPY_MODEL_3a85e48858b04398bd73c770f2cd79ef"],"layout":"IPY_MODEL_6ec5667f949546f19e938b801dc6454e"}},"50fc3f2b3faf4d728e2add5c11cfc807":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51e0a0ace806402fbdbf7703576d25bb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52a52e22bb43463c83ccd56278edb49a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"535ad410dfcc4daa9db3a26d54a353e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_51e0a0ace806402fbdbf7703576d25bb","placeholder":"​","style":"IPY_MODEL_79ffecceba7f4c9ea7061a156462678d","value":" 207M/207M [00:08&lt;00:00, 25.7MB/s]"}},"552269a2e190488b8c5ccbd111b27d2e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5aaf5d9b4b2f45fd8378ed0a097b4946":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fcb968068e54d719e9ebb9ca8a46f69","placeholder":"​","style":"IPY_MODEL_8171c9984ee347e8a7bf97366df1c1d1","value":"BratsCV_epoch_15.pt: 100%"}},"5c3fd6a52cfc47cb8f98a2893dc8521c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"604cfe51c90b46a88b6b5d1c30db53d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"66aff2997480405a8b1fcd89dfe8e649":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6ab6adf2f81145cd8013de09813ab5c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cd2a21390c54dce826d5c0c1bdd90ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cd65914eed846e4a84c9e008d5354e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_423ea92d3f764b31b5cc9517a0b34494","max":184608718,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f770dcc71e9d4263a1d25a0150869663","value":184608718}},"6dccbda6c7ac44778efdbac98b3e11c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6dd43c5befe84bbabb535c93ffe9a98b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ec5667f949546f19e938b801dc6454e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7142cbf7d6f84abe94dc9467a2e20aee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7304768659794bf19280216d3d68635c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7496b7349f644402a060ebe4357f1e6c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de5f5d9771374816baff84cb1bcc0ed2","placeholder":"​","style":"IPY_MODEL_7304768659794bf19280216d3d68635c","value":"BratsCV_epoch_10.pt: 100%"}},"759a9641cd234af282fd13a4c308b378":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76bb710b89e84c7a96a3aa413c516121":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7751f31624d34e45b7656f4ecad497ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79940d98186349e7b1a2b6164c059c82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79ffecceba7f4c9ea7061a156462678d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ff92b0a76814a68ad728b489acfed39":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8038ac8f6df742868be37cdfce377620":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4579438d457d4ae298fceef22c4f215e","max":184608718,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66aff2997480405a8b1fcd89dfe8e649","value":184608718}},"8171c9984ee347e8a7bf97366df1c1d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84f93c59f03a45bfadf277cdb4cd6226":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85f3f262837749a0be0c36d8f6c01128":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8686ae569d4c40089698c4ad5321937e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ba58bbd5756b4f74a0d259c621627737","IPY_MODEL_9fcbb17816fe495b9eb549e1be5a93df","IPY_MODEL_535ad410dfcc4daa9db3a26d54a353e6"],"layout":"IPY_MODEL_0e13f9cad0c147f49b40d38d1817dd54"}},"8a19294166874dd69ed87ab28deaf79b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d37c15c27b14da69d99a11abb5632a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9152c09ce22242e199333fadab088c5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e70fb89cf5bb40d7a801b9d8c6d10cc7","IPY_MODEL_334ac583728545e4bb53c5907b03cab2","IPY_MODEL_d15734cd3c434038b5779135ae20dae2"],"layout":"IPY_MODEL_b4b8230f99a14d4894ff5dadedeba129"}},"955965f1854142f78ccd727edc0c36f5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"959fc1624d3f4bb5bbddde7fd4385b02":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9750f4173efd4e878abbd32ac697a13b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d7b2a9c3b8c4e6597ace70ca37faa0f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9efe18375c3945f2a1f9b528e1699e69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5aaf5d9b4b2f45fd8378ed0a097b4946","IPY_MODEL_f573df12be704e20b6684bf61f60085a","IPY_MODEL_fc16357fea07423399b19b4dd2aa9d44"],"layout":"IPY_MODEL_e12ff59d61d146cdbbb08842ff2a6ab1"}},"9fcbb17816fe495b9eb549e1be5a93df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0101417913c04c2ab22688d7c4cc2244","max":206994458,"min":0,"orientation":"horizontal","style":"IPY_MODEL_06452cd57d0d46fcb0b7b4b620af7431","value":206994458}},"a4ff94f99bfa41f2b50938bc95162041":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6f5587506574aebb064896706609a9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7b46608184b46a2821b730845144cdd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa0e91ef105440218493c8683157abd4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab92c909985d4014ae0f2acfb069c726":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7496b7349f644402a060ebe4357f1e6c","IPY_MODEL_0dee265f717747349ab4d59d4dfb5012","IPY_MODEL_e489693f30674b62b8ab006bbac481d6"],"layout":"IPY_MODEL_e3e54575453f481388eb54d5bb5cb95f"}},"aba02c8406f241fca6a0196757273ad7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac678d71eafb41749553bccca9839954":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad80a1872a934874821b072973b95a4d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b10f2729cb0a458fa5ff2c7d859ab724":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b316a62934844a6dac2d14796ae781f4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b393678815784cc08989ea57d828c4b9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4b8230f99a14d4894ff5dadedeba129":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4f78045b2e84f2f83beae7fc3aa3082":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e47827be604c42b6b78a148ab663a09a","IPY_MODEL_d64dd359c027474a98eefa022738bf92","IPY_MODEL_d81836cff24e488d946f14b39258461a"],"layout":"IPY_MODEL_76bb710b89e84c7a96a3aa413c516121"}},"ba58bbd5756b4f74a0d259c621627737":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4ff94f99bfa41f2b50938bc95162041","placeholder":"​","style":"IPY_MODEL_0f53d5569aec4ad28c2bdab743cc51e3","value":"BratsCV_epoch_20.pt: 100%"}},"bb35836e1b7346e8b6c4bb4f32c7d714":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb417705b6784c8fb000d91d69475e49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ab6adf2f81145cd8013de09813ab5c9","placeholder":"​","style":"IPY_MODEL_2447c1f91098423fb1171cb67a8029d1","value":"BratsCV_epoch_5.pt: 100%"}},"bbf566158f134821953f2054253cb9de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bc4b2eb144f2471e87fd39b7054bdc92":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1db8fd726df48d4a26bf2f7cab9ea33":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3b8d6460771547d397adabb40db58016","IPY_MODEL_6cd65914eed846e4a84c9e008d5354e2","IPY_MODEL_fad750b9adb548369af2ec7d0b75d267"],"layout":"IPY_MODEL_6cd2a21390c54dce826d5c0c1bdd90ca"}},"c30b4b79776f43e2af22beab637aefa4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c547671ecdee43538c4e0b125169a84f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d7b2a9c3b8c4e6597ace70ca37faa0f","placeholder":"​","style":"IPY_MODEL_8d37c15c27b14da69d99a11abb5632a0","value":"BratsCV_epoch_25.pt: 100%"}},"c5fe4eeb165143fcbd692c7ca621b1e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_50fc3f2b3faf4d728e2add5c11cfc807","max":206994458,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d2662596fb2740f597399556464db6ae","value":206994458}},"c9ea97383ac845c1aa0c6b151262f4f0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfafa4ad0b2b4a9aaa4c2d67a3dcd102":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c30b4b79776f43e2af22beab637aefa4","max":206994458,"min":0,"orientation":"horizontal","style":"IPY_MODEL_17bf6e890bd84eecb79d64ac39e71485","value":178257920}},"d15734cd3c434038b5779135ae20dae2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa0e91ef105440218493c8683157abd4","placeholder":"​","style":"IPY_MODEL_ad80a1872a934874821b072973b95a4d","value":" 185M/185M [00:16&lt;00:00, 25.5MB/s]"}},"d2662596fb2740f597399556464db6ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d64dd359c027474a98eefa022738bf92":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b393678815784cc08989ea57d828c4b9","max":184608718,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bbf566158f134821953f2054253cb9de","value":184608718}},"d81836cff24e488d946f14b39258461a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6dd43c5befe84bbabb535c93ffe9a98b","placeholder":"​","style":"IPY_MODEL_379cf7850a6d4b2c8a7b2b7f9e25295e","value":" 185M/185M [00:16&lt;00:00, 20.7MB/s]"}},"d957df81de0c4688a963ae08d186ebfa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd0e807d0022412b9af605c9e2dd1571","placeholder":"​","style":"IPY_MODEL_3f245fdd02064c94b19f923e921080c3","value":" 207M/207M [00:08&lt;00:00, 25.6MB/s]"}},"dcbbe950d8bf47c6a5fbfa1054500cc6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd0e807d0022412b9af605c9e2dd1571":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de5f5d9771374816baff84cb1bcc0ed2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de79948d96394487a7c89640a66f7f67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_30a5ebdb8d5b4d0fab4c6a27010a94af","IPY_MODEL_cfafa4ad0b2b4a9aaa4c2d67a3dcd102","IPY_MODEL_e97d7422515347cbb76c2d9c8e5294e5"],"layout":"IPY_MODEL_31150334d6f94bdc861f2cbc2140083a"}},"e0c787d4ca664b25a13b6bd06322aa4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_955965f1854142f78ccd727edc0c36f5","placeholder":"​","style":"IPY_MODEL_aba02c8406f241fca6a0196757273ad7","value":"BratsCV_best.pt: 100%"}},"e12ff59d61d146cdbbb08842ff2a6ab1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3e54575453f481388eb54d5bb5cb95f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e47827be604c42b6b78a148ab663a09a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48a92b6ea58148eea8beac5634e68697","placeholder":"​","style":"IPY_MODEL_a7b46608184b46a2821b730845144cdd","value":"BratsCV_best.pt: 100%"}},"e489693f30674b62b8ab006bbac481d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44cfc4db605f4b31882ba634719cf445","placeholder":"​","style":"IPY_MODEL_fe5fd0790d8a4a81b33c25851425946e","value":" 207M/207M [00:09&lt;00:00, 22.6MB/s]"}},"e4fd195805604064950f941d03b9c50a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9ea97383ac845c1aa0c6b151262f4f0","placeholder":"​","style":"IPY_MODEL_7ff92b0a76814a68ad728b489acfed39","value":" 185M/185M [00:20&lt;00:00, 16.4MB/s]"}},"e70fb89cf5bb40d7a801b9d8c6d10cc7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a19294166874dd69ed87ab28deaf79b","placeholder":"​","style":"IPY_MODEL_759a9641cd234af282fd13a4c308b378","value":"BratsCV_best.pt: 100%"}},"e8aaac2b86034c29a52ed5f6c2071d13":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85f3f262837749a0be0c36d8f6c01128","placeholder":"​","style":"IPY_MODEL_604cfe51c90b46a88b6b5d1c30db53d9","value":"BratsCV_epoch_30_20250502_153355.pt: 100%"}},"e97d7422515347cbb76c2d9c8e5294e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52a52e22bb43463c83ccd56278edb49a","placeholder":"​","style":"IPY_MODEL_30cb54e6e8d14532aa544cd5227f0900","value":" 178M/207M [00:23&lt;00:03, 7.42MB/s]"}},"ee904822cfb4460db7725590b50992b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_84f93c59f03a45bfadf277cdb4cd6226","max":206994458,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1485ba524e2d48cc95f0872593022113","value":206994458}},"f573df12be704e20b6684bf61f60085a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc4b2eb144f2471e87fd39b7054bdc92","max":206994458,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f85f9d2032dd41e5b2a6b69fe0818472","value":206994458}},"f770dcc71e9d4263a1d25a0150869663":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f85f9d2032dd41e5b2a6b69fe0818472":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fad750b9adb548369af2ec7d0b75d267":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b10f2729cb0a458fa5ff2c7d859ab724","placeholder":"​","style":"IPY_MODEL_29332ea751b746a98098a4782ab837ef","value":" 185M/185M [00:23&lt;00:00, 7.47MB/s]"}},"fc16357fea07423399b19b4dd2aa9d44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a064552196245daa2dce23ce3f17e89","placeholder":"​","style":"IPY_MODEL_dcbbe950d8bf47c6a5fbfa1054500cc6","value":" 207M/207M [00:00&lt;00:00, 225MB/s]"}},"fe5fd0790d8a4a81b33c25851425946e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1299795,"sourceType":"datasetVersion","datasetId":751906}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport logging\n\nimport sys\nimport random\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nfrom matplotlib import cm\nimport matplotlib.animation as anim\nimport matplotlib.patches as mpatches\nimport matplotlib.gridspec as gridspec\n\nimport nibabel as nib\nimport torch.nn as nn\nimport torch.optim as optim\nimport gc\nimport torch\n\nimport torch.nn.functional as F\nimport os\nimport numpy as np\nimport nibabel as nib\nimport torch\nfrom torch.utils.data import Dataset\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\nfrom tqdm import tqdm\n\nfrom torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torch.cuda.amp import autocast, GradScaler\nfrom sklearn.metrics import confusion_matrix\nimport kagglehub\nfrom huggingface_hub import HfApi, create_repo\nimport os\nfrom datetime import datetime\nfrom kaggle_secrets import UserSecretsClient\nimport cv2","metadata":{"id":"H7a3q0uFV6KS","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T17:32:33.236654Z","iopub.execute_input":"2025-07-01T17:32:33.236952Z","iopub.status.idle":"2025-07-01T17:33:06.735533Z","shell.execute_reply.started":"2025-07-01T17:32:33.236931Z","shell.execute_reply":"2025-07-01T17:33:06.734974Z"}},"outputs":[{"name":"stderr","text":"2025-07-01 17:32:50.320460: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751391170.724829      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751391170.845427      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Model creation","metadata":{}},{"cell_type":"code","source":"class ImprovedUNet3D(nn.Module):\n    def __init__(self, in_channels=4, out_channels=4, base_filters=16):\n        super(ImprovedUNet3D, self).__init__()\n\n        self.enc1 = self._make_layer(in_channels, base_filters)\n        self.pool1 = nn.MaxPool3d(kernel_size=2, stride=2)\n\n        self.enc2 = self._make_layer(base_filters, base_filters*2)\n        self.pool2 = nn.MaxPool3d(kernel_size=2, stride=2)\n\n        self.enc3 = self._make_layer(base_filters*2, base_filters*4)\n\n        self.upconv2 = nn.ConvTranspose3d(base_filters*4, base_filters*2, kernel_size=2, stride=2)\n        self.dec2 = self._make_layer(base_filters*4, base_filters*2)\n\n        self.upconv1 = nn.ConvTranspose3d(base_filters*2, base_filters, kernel_size=2, stride=2)\n        self.dec1 = self._make_layer(base_filters*2, base_filters)\n\n        self.dropout = nn.Dropout3d(0.10)\n        self.final_conv = nn.Conv3d(base_filters, out_channels, kernel_size=1)\n\n        self._initialize_weights()\n\n    def _make_layer(self, in_channels, out_channels):\n        \"\"\"Create a residual block\"\"\"\n        return nn.Sequential(\n            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.InstanceNorm3d(out_channels),\n            nn.LeakyReLU(inplace=True),\n            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.InstanceNorm3d(out_channels),\n            nn.LeakyReLU(inplace=True)\n        )\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv3d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.InstanceNorm3d):\n                if m.weight is not None:\n                    nn.init.constant_(m.weight, 1)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        enc1_out = self.enc1(x)\n        p1 = self.pool1(enc1_out)\n\n        enc2_out = self.enc2(p1)\n        p2 = self.pool2(enc2_out)\n\n        enc3_out = self.enc3(p2)\n\n        up2 = self.upconv2(enc3_out)\n\n        diffY = enc2_out.size()[2] - up2.size()[2]\n        diffX = enc2_out.size()[3] - up2.size()[3]\n        diffZ = enc2_out.size()[4] - up2.size()[4]\n\n        up2 = F.pad(up2, [\n            diffZ // 2, diffZ - diffZ // 2,\n            diffX // 2, diffX - diffX // 2,\n            diffY // 2, diffY - diffY // 2\n        ])\n        concat2 = torch.cat([up2, enc2_out], dim=1)\n        dec2_out = self.dec2(concat2)\n\n        up1 = self.upconv1(dec2_out)\n\n        diffY = enc1_out.size()[2] - up1.size()[2]\n        diffX = enc1_out.size()[3] - up1.size()[3]\n        diffZ = enc1_out.size()[4] - up1.size()[4]\n\n        up1 = F.pad(up1, [\n            diffZ // 2, diffZ - diffZ // 2,\n            diffX // 2, diffX - diffX // 2,\n            diffY // 2, diffY - diffY // 2\n        ])\n        concat1 = torch.cat([up1, enc1_out], dim=1)\n        dec1_out = self.dec1(concat1)\n\n        x = self.dropout(dec1_out)\n\n        out = self.final_conv(x)\n\n        return out\n\nmodel = ImprovedUNet3D(base_filters=16)\ntotal_params = sum(p.numel() for p in model.parameters())\nprint(f\"Total parameters: {total_params:,}\")\nsize_in_bytes = total_params * 4\nsize_in_mb = size_in_bytes / (1024 ** 2)\nprint(f\"Model size (inference): {size_in_mb:.2f} MB\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T17:39:47.883686Z","iopub.execute_input":"2025-07-01T17:39:47.884390Z","iopub.status.idle":"2025-07-01T17:39:47.905825Z","shell.execute_reply.started":"2025-07-01T17:39:47.884366Z","shell.execute_reply":"2025-07-01T17:39:47.905220Z"}},"outputs":[{"name":"stdout","text":"Total parameters: 340,596\nModel size (inference): 1.30 MB\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## Dataset processing","metadata":{"id":"KG92aYgJNSmx"}},{"cell_type":"code","source":"class BrainTumorDataset(Dataset):\n    def __init__(self, patient_list, data_dir, is_train=True, transform=None, slice_range=(60, 100)):\n        self.data_dir = data_dir              # Path to directory containing patient subfolders\n        self.is_train = is_train              # Flag indicating training or inference phase\n        self.transform = transform            # Optional data augmentations or preprocessing\n        # List of MRI modalities\n        self.modalities = [\"flair\", \"t1\", \"t1ce\", \"t2\"]\n\n        # Filter out any CSV files and exclude problematic patient 355\n        self.patients = [p for p in patient_list if not p.endswith(\".csv\") and \"355\" not in p]\n\n        # Range of axial slices to load (start_slice, end_slice)\n        self.slice_range = slice_range       \n\n    def load_nifti(self, path):\n        # Load NIfTI file from disk using nibabel and return as numpy float32 array\n        nifti_img = nib.load(path)\n        return np.array(nifti_img.get_fdata(), dtype=np.float32)\n\n    def __len__(self):\n        return len(self.patients)\n\n    def __getitem__(self, idx):\n        patient_id = self.patients[idx]\n\n        # Safeguard: skip patient 355 if encountered\n        if patient_id == \"BraTS20_Training_355\":\n            return None\n        # Construct path to this patient's data folder\n        patient_path = os.path.join(self.data_dir, patient_id)\n        # Load and preprocess each MRI modality\n        images = []\n        for modality in self.modalities:\n            img_path = os.path.join(patient_path, f\"{patient_id}_{modality}.nii\")\n            img = self.load_nifti(img_path)\n            # Crop to the specified slice range along the axial (third) dimension\n            start_slice, end_slice = self.slice_range\n            img = img[:, :, start_slice:end_slice]\n            # Apply z-score normalization for stability; avoid division by zero\n            if np.std(img) > 0:\n                img = (img - np.mean(img)) / np.std(img)\n            else:\n                img = np.zeros_like(img)\n\n            images.append(img)\n        # Stack the four modalities into a single tensor of shape (4, H, W, D)\n        images = np.stack(images, axis=0)\n        # Load segmentation mask if in training mode\n        if self.is_train:\n            # Possible filenames for segmentation masks\n            seg_paths = [\n                os.path.join(patient_path, f\"{patient_id}_seg.nii\"),\n                os.path.join(patient_path, f\"{patient_id}_Segm.nii\"),\n                os.path.join(patient_path, f\"{patient_id}_Segmentation.nii\")\n            ]\n            # Select the first existing segmentation file\n            seg_path = next((path for path in seg_paths if os.path.exists(path)), None)\n\n            if seg_path is None:\n                # Issue warning and create empty mask if not found\n                print(f\"Warning: No segmentation file found for patient {patient_id}.\")\n                mask = np.zeros_like(images[0], dtype=np.int64)\n            else:\n                # Load and crop mask to the same slice range\n                mask = self.load_nifti(seg_path)\n                mask = mask[:, :, self.slice_range[0]:self.slice_range[1]]\n                # Reassign label '4' (if present) to 3 for enhancing tumor\n                mask[mask == 4] = 3\n        else:\n            mask = None  # No mask needed for inference\n        # Apply optional transformations (e.g., augmentation) before tensor conversion\n        if self.transform is not None:\n            if self.is_train:\n                # When training, transform both image and mask\n                transformed = self.transform(image=images, mask=mask)\n                images, mask = transformed['image'], transformed['mask']\n            else:\n                # During inference, only transform the image\n                transformed = self.transform(image=images)\n                images = transformed['image']\n        # Convert numpy arrays to PyTorch tensors\n        if not isinstance(images, torch.Tensor):\n            images = torch.tensor(images, dtype=torch.float32)\n        if self.is_train and mask is not None:\n            # Convert mask to long tensor for use in loss functions\n            if not isinstance(mask, torch.Tensor):\n                mask = torch.tensor(mask, dtype=torch.long)\n            else:\n                mask = mask.to(dtype=torch.long)\n\n        # Return (image, mask) tuple for training or image only for inference\n        return (images, mask) if self.is_train else images","metadata":{"id":"aksbOCQKj-bc","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T17:33:48.983836Z","iopub.execute_input":"2025-07-01T17:33:48.984105Z","iopub.status.idle":"2025-07-01T17:33:48.995063Z","shell.execute_reply.started":"2025-07-01T17:33:48.984086Z","shell.execute_reply":"2025-07-01T17:33:48.994305Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### Download the dataset","metadata":{}},{"cell_type":"code","source":"path = kagglehub.dataset_download(\"awsaf49/brats20-dataset-training-validation\")\ndata_dir = path + \"/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData\"\ntrain_dir = path + \"/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData\"\nval_dir = path +\"/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData\"","metadata":{"id":"IF9IJJnyN2Nh","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T17:33:52.716865Z","iopub.execute_input":"2025-07-01T17:33:52.717130Z","iopub.status.idle":"2025-07-01T17:33:52.838899Z","shell.execute_reply.started":"2025-07-01T17:33:52.717110Z","shell.execute_reply":"2025-07-01T17:33:52.838339Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### visualization of the dataset","metadata":{}},{"cell_type":"code","source":"def visualize_samples_with_colors(data_dir, BraTS20_Training_00n):\n    flair = data_dir+ BraTS20_Training_00n + BraTS20_Training_00n +'_flair.nii'\n    mask = data_dir+ BraTS20_Training_00n + BraTS20_Training_00n +'_seg.nii'\n    t1 = data_dir+ BraTS20_Training_00n + BraTS20_Training_00n +'_t1.nii'\n    t2 = data_dir+ BraTS20_Training_00n + BraTS20_Training_00n +'_t2.nii'\n    t1ce = data_dir+ BraTS20_Training_00n + BraTS20_Training_00n +'_t1ce.nii'\n\n    flair_img = nib.load(flair)\n    flair_img = np.asanyarray(flair_img.dataobj)\n    flair_img = np.rot90(flair_img)\n\n    sample_mask = nib.load(mask)\n    sample_mask = np.asanyarray(sample_mask.dataobj)\n    sample_mask = np.rot90(sample_mask)\n\n    t1_img = nib.load(t1)\n    t1_img = np.asanyarray(t1_img.dataobj)\n    t1_img  = np.rot90(t1_img)\n\n    t2_img = nib.load(t2)\n    t2_img = np.asanyarray(t2_img.dataobj)\n    t2_img  = np.rot90(t2_img)\n\n    t1ce_img = nib.load(t1ce)\n    t1ce_img = np.asanyarray(t1ce_img.dataobj)\n    t1ce_img  = np.rot90(t1ce_img)\n\n    mask_WT = sample_mask.copy()\n    mask_WT[mask_WT == 1] = 1\n    mask_WT[mask_WT == 2] = 1\n    mask_WT[mask_WT == 4] = 1\n\n    mask_TC = sample_mask.copy()\n    mask_TC[mask_TC == 1] = 1\n    mask_TC[mask_TC == 2] = 0\n    mask_TC[mask_TC == 4] = 1\n\n    mask_ET = sample_mask.copy()\n    mask_ET[mask_ET == 1] = 0\n    mask_ET[mask_ET == 2] = 0\n    mask_ET[mask_ET == 4] = 1\n\n    fig = plt.figure(figsize=(20, 10))\n\n    gs = gridspec.GridSpec(nrows=2, ncols=5, height_ratios=[1, 1.5])\n\n    fontsize = 10\n    ax0 = fig.add_subplot(gs[0, 0])\n    flair = ax0.imshow(flair_img[:,:,65], cmap='bone')\n    ax0.set_title(\"FLAIR\", fontsize = fontsize, weight='bold', y=-0.2)\n    fig.colorbar(flair)\n\n    ax1 = fig.add_subplot(gs[0, 1])\n    t1 = ax1.imshow(t1_img[:,:,65], cmap='bone')\n    ax1.set_title(\"T1\", fontsize = fontsize, weight='bold', y=-0.2)\n    fig.colorbar(t1)\n    \n    ax2 = fig.add_subplot(gs[0, 2])\n    t2 = ax2.imshow(t2_img[:,:,65], cmap='bone')\n    ax2.set_title(\"T2\", fontsize = fontsize, weight='bold', y=-0.2)\n    fig.colorbar(t2)\n\n    ax3 = fig.add_subplot(gs[0, 3])\n    t1ce = ax3.imshow(t1ce_img[:,:,65], cmap='bone')\n    ax3.set_title(\"T1 contrast\", fontsize = fontsize, weight='bold', y=-0.2)\n    fig.colorbar(t1ce)\n\n    ax4 = fig.add_subplot(gs[1, 1:3])\n\n    l1 = ax4.imshow(mask_WT[:,:,65], cmap='summer',)\n    l2 = ax4.imshow(np.ma.masked_where(mask_TC[:,:,65]== False,  mask_TC[:,:,65]), cmap='rainbow', alpha=0.6)\n    l3 = ax4.imshow(np.ma.masked_where(mask_ET[:,:,65] == False, mask_ET[:,:,65]), cmap='winter', alpha=0.6)\n\n    ax4.set_title(\"\", fontsize=fontsize, weight='bold', y=-0.1)\n\n    _ = [ax.set_axis_off() for ax in [ax0,ax1,ax2,ax3, ax4]]\n\n    colors = [im.cmap(im.norm(1)) for im in [l1,l2, l3]]\n    labels = ['Non-Enhancing tumor core', 'Peritumoral Edema ', 'GD-enhancing tumor']\n    patches = [ mpatches.Patch(color=colors[i], label=f\"{labels[i]}\") for i in range(len(labels))]\n    plt.legend(handles=patches, bbox_to_anchor=(1.1, 0.65), loc=2, borderaxespad=0.4,fontsize = 'xx-large',\n              title='Mask Labels', title_fontsize=18, edgecolor=\"black\",  facecolor='#c5c6c7')\n\n    plt.suptitle(\"Multimodal Scans -  Data | Manually-segmented mask - Target\", fontsize=20, weight='bold')\n\n    fig.savefig(\"data_sample.png\", format=\"png\",  pad_inches=0.2, transparent=False, bbox_inches='tight')\n    fig.savefig(\"data_sample.svg\", format=\"svg\",  pad_inches=0.2, transparent=False, bbox_inches='tight')","metadata":{"id":"kKhctvIIUz4l","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T17:33:53.665326Z","iopub.execute_input":"2025-07-01T17:33:53.665570Z","iopub.status.idle":"2025-07-01T17:33:53.677947Z","shell.execute_reply.started":"2025-07-01T17:33:53.665551Z","shell.execute_reply":"2025-07-01T17:33:53.677307Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Dataset splitting and processing\n","metadata":{"id":"4A-UpenYn-I6"}},{"cell_type":"code","source":"train_patient_dirs = os.listdir(train_dir)\ntest_patient_dirs = os.listdir(val_dir)\nall_train_patients = []\nfor p in train_patient_dirs:\n    if os.path.isdir(os.path.join(train_dir, p)):\n        all_train_patients.append(p)\nall_train_patients.sort()\n\nall_test_patients = []\nfor p in test_patient_dirs:\n    if os.path.isdir(os.path.join(val_dir, p)):\n        all_test_patients.append(p)\nall_test_patients.sort()\n\n\nslice_range = (0, 155)\nslice_range = (0, 155)\ntrain_patients, val_patients = train_test_split(all_train_patients, test_size=0.2, random_state=42)\ntrain_dataset = BrainTumorDataset(\n    patient_list=train_patients,\n    data_dir=train_dir,\n    slice_range=slice_range,\n    transform=None\n)\n\nval_dataset = BrainTumorDataset(\n    patient_list=val_patients,\n    data_dir=train_dir,\n    slice_range=slice_range\n)\n\ntest_dataset = BrainTumorDataset(\n    patient_list=all_test_patients,\n    data_dir=val_dir,\n    is_train=False,\n    slice_range=slice_range\n)\nprint(f\"Using {len(train_dataset)} training patients and {len(val_dataset)} test patients\")\n\ntrain_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=2)\n\nsample_img, sample_mask = next(iter(train_loader))\nprint(f\"Train set image dimension: {sample_img.shape}\")  # Should be smaller now\nprint(f\"Train set segmentation dimension: {sample_mask.shape}\")\n\nsample_img, sample_mask = next(iter(val_loader))\nprint(\"Validation set image dimension:\", sample_img.shape)\nprint(\"Validation set segmentation dimension:\", sample_mask.shape)\n\nsample_img = next(iter(test_loader))\nprint(\"Test set image dimension:\", sample_img.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tW9R8xsgn5pq","outputId":"9d6fa6f1-2932-4d46-b1a0-96ea1bcb4f33","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T17:33:55.686418Z","iopub.execute_input":"2025-07-01T17:33:55.687230Z","iopub.status.idle":"2025-07-01T17:34:14.348263Z","shell.execute_reply.started":"2025-07-01T17:33:55.687205Z","shell.execute_reply":"2025-07-01T17:34:14.347300Z"}},"outputs":[{"name":"stdout","text":"Using 294 training patients and 74 test patients\nTrain set image dimension: torch.Size([2, 4, 240, 240, 155])\nTrain set segmentation dimension: torch.Size([2, 240, 240, 155])\nValidation set image dimension: torch.Size([1, 4, 240, 240, 155])\nValidation set segmentation dimension: torch.Size([1, 240, 240, 155])\nTest set image dimension: torch.Size([1, 4, 240, 240, 155])\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### set devices","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nif torch.cuda.is_available():\n    torch.cuda.empty_cache()\n    gc.collect()\n    for i in range(5): \n        gc.collect()\n        torch.cuda.empty_cache()\n\n    num_gpus = torch.cuda.device_count()\n    print(f\"Using {num_gpus} GPUs for training.\" if num_gpus > 1 else\n          f\"Using {torch.cuda.get_device_name(0)} for training.\")\n\n    # Print available and total memory\n    if hasattr(torch.cuda, 'get_device_properties'):\n        for i in range(num_gpus):\n            prop = torch.cuda.get_device_properties(i)\n            print(f\"GPU {i}: {prop.name}\")\n            print(f\"  Total memory: {prop.total_memory / 1024**3:.2f} GB\")\n            print(f\"  Available memory: {torch.cuda.memory_reserved(i) / 1024**3:.2f} GB reserved\")\n            print(f\"  Allocated memory: {torch.cuda.memory_allocated(i) / 1024**3:.2f} GB\")\nelse:\n    print(\"Using CPU for training.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5EL269D_OdDi","outputId":"90c6ecb2-a785-4144-ccb0-8a7cae6cbd30","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T17:34:42.241872Z","iopub.execute_input":"2025-07-01T17:34:42.242596Z","iopub.status.idle":"2025-07-01T17:34:43.993052Z","shell.execute_reply.started":"2025-07-01T17:34:42.242567Z","shell.execute_reply":"2025-07-01T17:34:43.992397Z"}},"outputs":[{"name":"stdout","text":"Using 2 GPUs for training.\nGPU 0: Tesla T4\n  Total memory: 14.74 GB\n  Available memory: 0.00 GB reserved\n  Allocated memory: 0.00 GB\nGPU 1: Tesla T4\n  Total memory: 14.74 GB\n  Available memory: 0.00 GB reserved\n  Allocated memory: 0.00 GB\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def dice_coefficient_soft(pred_probs, target, num_classes=4, smooth=1e-6):\n    dice_scores = []\n    target_one_hot = F.one_hot(target, num_classes=num_classes).permute(0, 4, 1, 2, 3).float()\n    for class_id in range(num_classes):\n        pred_class = pred_probs[:, class_id, ...]\n        target_class = target_one_hot[:, class_id, ...]\n        intersection = (pred_class * target_class).sum(dim=[1, 2, 3]) # Sum over spatial dims\n        pred_sum = pred_class.sum(dim=[1, 2, 3])\n        target_sum = target_class.sum(dim=[1, 2, 3])\n        dice_score_class = (2. * intersection + smooth) / (pred_sum + target_sum + smooth)\n        dice_scores.append(dice_score_class.mean())\n    dice_scores = torch.stack(dice_scores)\n    return dice_scores.mean() \n\n# Modified DiceLoss using Soft Dice\nclass DiceLoss(nn.Module):\n    def __init__(self, num_classes=4, smooth=1e-6):\n        super(DiceLoss, self).__init__()\n        self.num_classes = num_classes\n        self.smooth = smooth\n\n    def forward(self, y_pred_logits, y_true):\n        y_pred_probs = F.softmax(y_pred_logits, dim=1)\n        dice = dice_coefficient_soft(y_pred_probs, y_true, num_classes=self.num_classes, smooth=self.smooth)\n        return 1 - dice\n\nclass CombinedLoss(nn.Module):\n    def __init__(self, weight_dice=0.7, weight_ce=0.3, num_classes=4):\n        super(CombinedLoss, self).__init__()\n        self.weight_dice = weight_dice\n        self.weight_ce = weight_ce\n        self.dice_loss = DiceLoss(num_classes=num_classes)\n        self.ce_loss = nn.CrossEntropyLoss()\n\n    def forward(self, inputs_logits, targets):\n        ce_loss_value = self.ce_loss(inputs_logits, targets)\n        dice_loss_value = self.dice_loss(inputs_logits, targets)\n        return self.weight_ce * ce_loss_value + self.weight_dice * dice_loss_value\n\ndef dice_coefficient_metric(pred_labels, target_labels, num_classes=4, smooth=1e-6):\n    dice_scores = []\n    for class_id in range(num_classes):\n        pred_class = (pred_labels == class_id).float()\n        target_class = (target_labels == class_id).float()\n        intersection = (pred_class * target_class).sum()\n        dice_score = (2. * intersection + smooth) / (pred_class.sum() + target_class.sum() + smooth)\n        dice_scores.append(dice_score)\n    dice_scores = torch.stack(dice_scores)\n    return dice_scores.mean()","metadata":{"id":"BArIB62TSksv","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T17:34:43.994003Z","iopub.execute_input":"2025-07-01T17:34:43.994321Z","iopub.status.idle":"2025-07-01T17:34:44.003586Z","shell.execute_reply.started":"2025-07-01T17:34:43.994303Z","shell.execute_reply":"2025-07-01T17:34:44.003081Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Create the model","metadata":{}},{"cell_type":"code","source":"model = ImprovedUNet3D(in_channels=4, out_channels=4, base_filters=16)\nmodel = torch.nn.DataParallel(model)\nmodel.to(device)\n# Use mixed precision for memory efficiency\nuse_amp = True\nscaler = torch.amp.GradScaler(\"cuda\", enabled=\"use_amp\")\ncriterion = CombinedLoss()\noptimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=5e-3)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=1e-6)","metadata":{"id":"OGQYkGhUSjM5","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T17:40:01.896658Z","iopub.execute_input":"2025-07-01T17:40:01.896968Z","iopub.status.idle":"2025-07-01T17:40:01.913482Z","shell.execute_reply.started":"2025-07-01T17:40:01.896946Z","shell.execute_reply":"2025-07-01T17:40:01.913004Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import torch\n\ndef train_one_epoch(model, dataloader, optimizer, criterion, device, scaler=None):\n    \"\"\"\n    Train the model for one epoch.\n    Args:\n        model: PyTorch model to train.\n        dataloader: DataLoader providing (inputs, targets).\n        optimizer: Optimizer for parameter updates.\n        criterion: Loss function to compute training loss.\n        device: Torch device (cpu or cuda).\n        scaler: Optional GradScaler for mixed precision.\n    Returns:\n        avg_loss: Average training loss over batches.\n        avg_dice: Average Dice score over batches.\n        avg_dice_per_class: Tensor of average Dice per class.\n    \"\"\"\n    use_amp = scaler is not None  # Flag whether to use automatic mixed precision\n    model.train()                 # Set model to training mode\n    epoch_loss = 0.0              # Cumulative loss for the epoch\n    dice_score = 0.0              # Cumulative Dice score\n    dice_per_class = torch.zeros(4, device=device)  # Sum of per-class Dice scores\n    batch_count = 0               # Number of processed batches\n\n    for i, (inputs, targets) in enumerate(dataloader):\n        # Move data to target device\n        inputs = inputs.to(device)\n        targets = targets.to(device)\n        optimizer.zero_grad()      # Reset gradients\n\n        if use_amp:\n            # Use mixed precision context\n            with torch.cuda.amp.autocast(enabled=True):\n                outputs = model(inputs)             # Forward pass\n                loss = criterion(outputs, targets)  # Compute loss\n            # Scale loss, backpropagate, and unscale gradients\n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            # Gradient clipping for stability\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.5)\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            outputs = model(inputs)                 # Forward pass\n            loss = criterion(outputs, targets)      # Compute loss\n            loss.backward()                         # Backpropagate\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.5)\n            optimizer.step()                        # Update parameters\n\n        epoch_loss += loss.item()  # Accumulate loss\n\n        # Generate predictions: handle multi-class vs binary\n        if outputs.shape[1] > 1:\n            _, preds = torch.max(outputs, dim=1)\n        else:\n            preds = (torch.sigmoid(outputs) > 0.5).float()\n\n        # Compute overall Dice score for the batch\n        dice = dice_coefficient_metric(preds, targets)\n        dice_score += dice.item()\n\n        # Compute per-class Dice scores\n        class_dice_scores = []\n        for class_id in range(4):\n            pred_class = (preds == class_id).float()\n            target_class = (targets == class_id).float()\n            intersection = (pred_class * target_class).sum()\n            class_dice = (2. * intersection + 1e-6) / (pred_class.sum() + target_class.sum() + 1e-6)\n            dice_per_class[class_id] += class_dice.item()\n            class_dice_scores.append(class_dice.item())\n\n        batch_count += 1\n        # Print progress every 5 batches\n        if (i + 1) % 5 == 0:\n            print(f\"Batch {i+1}/{len(dataloader)}, Loss: {loss.item():.4f}, Dice: {dice:.4f}\")\n            print(f\"  Class Dice: Background: {class_dice_scores[0]:.4f}, \\\n                  NCR: {class_dice_scores[1]:.4f}, ED: {class_dice_scores[2]:.4f}, ET: {class_dice_scores[3]:.4f}\")\n\n        # Free memory\n        del inputs, targets, outputs, preds\n        torch.cuda.empty_cache()\n\n    # Compute average metrics over all batches\n    avg_loss = epoch_loss / batch_count\n    avg_dice = dice_score / batch_count\n    avg_dice_per_class = dice_per_class / batch_count\n\n    return avg_loss, avg_dice, avg_dice_per_class\n\n\ndef validate_one_epoch(model, dataloader, criterion, device, scaler=None):\n    \"\"\"\n    Validate the model for one epoch without gradient updates.\n    Args:\n        model: PyTorch model to evaluate.\n        dataloader: DataLoader providing (inputs, targets).\n        criterion: Loss function to compute validation loss.\n        device: Torch device (cpu or cuda).\n        scaler: Optional GradScaler for mixed precision during validation.\n    Returns:\n        avg_loss: Average validation loss.\n        avg_dice: Average Dice score.\n        avg_dice_per_class: Tensor of average Dice per class.\n    \"\"\"\n    model.eval()  # Set model to evaluation mode\n    epoch_loss = 0.0\n    dice_score = 0.0\n    dice_per_class = torch.zeros(4, device=device)\n    batch_count = 0\n\n    with torch.no_grad():  # Disable gradient calculation\n        for i, (inputs, targets) in enumerate(dataloader):\n            inputs = inputs.to(device)\n            targets = targets.to(device)\n\n            # Determine number of classes from criterion if available\n            if hasattr(criterion, 'dice_loss') and hasattr(criterion.dice_loss, 'num_classes'):\n                num_classes = criterion.dice_loss.num_classes\n            else:\n                num_classes = 4  # Fallback to 4 classes\n\n            # Forward pass under mixed precision if scaler provided\n            with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n                outputs = model(inputs)             # Logits from model\n                loss = criterion(outputs, targets)  # Loss computation\n\n            epoch_loss += loss.item()\n\n            # Get predictions for metric computation\n            if outputs.shape[1] > 1:\n                _, preds = torch.max(outputs, dim=1)\n            else:\n                preds = (torch.sigmoid(outputs) > 0.5).float()\n\n            # Compute overall Dice score\n            dice = dice_coefficient_metric(preds, targets, num_classes=num_classes)\n            dice_score += dice.item()\n\n            # Accumulate per-class Dice scores\n            for class_id in range(num_classes):\n                pred_class = (preds == class_id).float()\n                target_class = (targets == class_id).float()\n                intersection = (pred_class * target_class).sum()\n                class_dice = (2. * intersection + 1e-6) / (pred_class.sum() + target_class.sum() + 1e-6)\n                dice_per_class[class_id] += class_dice.item()\n\n            batch_count += 1\n            # Free memory\n            del inputs, targets, outputs, preds\n            torch.cuda.empty_cache()\n\n    # Average validation metrics\n    avg_loss = epoch_loss / batch_count\n    avg_dice = dice_score / batch_count\n    avg_dice_per_class = dice_per_class / batch_count\n\n    return avg_loss, avg_dice, avg_dice_per_class\n\n\nclass EarlyStopping:\n    \"\"\"\n    Early stops the training if validation loss doesn't improve after a given patience.\n    \"\"\"\n    def __init__(self, patience=7, min_delta=0.001):\n        self.patience = patience      # Number of epochs to wait after last improvement\n        self.min_delta = min_delta    # Minimum change to qualify as improvement\n        self.counter = 0              # Counter for epochs without improvement\n        self.best_score = None        # Best observed validation loss\n        self.early_stop = False       # Flag to indicate whether to stop training\n\n    def __call__(self, val_loss):\n        # Initialize best_score at first call\n        if self.best_score is None:\n            self.best_score = val_loss\n        # If no significant improvement, increment counter\n        elif val_loss > self.best_score + self.min_delta:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True  # Trigger early stop\n        else:\n            # Improvement observed: reset counter and update best_score\n            self.best_score = val_loss\n            self.counter = 0","metadata":{"id":"tqH7BNSlSZiZ","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T17:34:55.529246Z","iopub.execute_input":"2025-07-01T17:34:55.530420Z","iopub.status.idle":"2025-07-01T17:34:55.549087Z","shell.execute_reply.started":"2025-07-01T17:34:55.530388Z","shell.execute_reply":"2025-07-01T17:34:55.548288Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\napi = HfApi()\nrepo_name = \"dugoalberto/3D_U_Net\"\ncheckpoint_dir = \"./checkpoints\"\nos.makedirs(checkpoint_dir, exist_ok=True)","metadata":{"id":"FNKNIiELT26M","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T17:34:57.921400Z","iopub.execute_input":"2025-07-01T17:34:57.921878Z","iopub.status.idle":"2025-07-01T17:34:58.057073Z","shell.execute_reply.started":"2025-07-01T17:34:57.921856Z","shell.execute_reply":"2025-07-01T17:34:58.056346Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Training (from new model)","metadata":{"id":"ds5nmMtnUw-G"}},{"cell_type":"code","source":"# Training loop with early stopping\nnum_epochs = 300  # Increased epochs with early stopping\nbest_val_dice = 0.0\nearly_stopping = EarlyStopping(patience=10)\n\n# Lists to store metrics\ntrain_losses = []\nval_losses = []\ntrain_dice_scores = []\nval_dice_scores = []\nlearning_rates = []\n\nfor epoch in range(num_epochs):\n    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n\n    # Train\n    train_loss, train_dice = train_one_epoch(model, train_loader, optimizer, criterion, device, scaler)\n    train_losses.append(train_loss)\n    train_dice_scores.append(train_dice)\n\n    # Update learning rate\n    current_lr = optimizer.param_groups[0]['lr']\n    learning_rates.append(current_lr)\n    if scheduler is not None and isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n            scheduler.step(val_loss)\n    else: \n        scheduler.step()\n\n    # Free memory before validation\n    torch.cuda.empty_cache()\n\n    # Validate\n    val_loss, val_dice = validate_one_epoch(model, val_loader, criterion, device)\n    val_losses.append(val_loss)\n    val_dice_scores.append(val_dice)\n\n    # Print epoch results\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Dice: {train_dice:.4f}\")\n    print(f\"Validation Loss: {val_loss:.4f}, Validation Dice: {val_dice:.4f}, LR: {current_lr:.6f}\")\n\n    if val_dice > best_val_dice:\n        best_val_dice = val_dice\n        best_model_path = os.path.join(checkpoint_dir, 'BratsCV_best.pt')\n        torch.save(model, best_model_path)\n        print(f\"Best model saved with Dice score: {best_val_dice:.4f}!\")\n\n        # Upload best model to Hugging Face\n        api.upload_file(\n            path_or_fileobj=best_model_path,\n            path_in_repo=\"BratsCV_best.pt\",\n            repo_id=repo_name,\n            token=hf_token\n        )\n        print(f\"Best model uploaded to Hugging Face!\")\n\n    # Save regular checkpoint every 5 epochs or final epoch\n    if (epoch + 1) % 5 == 0 or epoch == num_epochs - 1:\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        checkpoint_path = os.path.join(checkpoint_dir, f'BratsCV_epoch_{epoch+1}_{timestamp}.pt')\n\n        # Save model state dictionary and optimizer state\n        checkpoint = {\n            'epoch': epoch + 1,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n            'train_loss': train_loss,\n            'val_loss': val_loss,\n            'train_dice': train_dice,\n            'val_dice': val_dice,\n            'best_val_dice': best_val_dice,\n            'learning_rate': current_lr\n        }\n        torch.save(checkpoint, checkpoint_path)\n\n        # Upload checkpoint to Hugging Face\n        try:\n            api.upload_file(\n                path_or_fileobj=checkpoint_path,\n                path_in_repo=f\"checkpoints/BratsCV_epoch_{epoch+1}.pt\",\n                repo_id=repo_name,\n                token=hf_token\n            )\n            print(f\"Checkpoint for epoch {epoch+1} uploaded to Hugging Face!\")\n        except Exception as e:\n            print(f\"Error uploading checkpoint to Hugging Face: {e}\")\n\n    early_stopping(val_loss)\n    if early_stopping.early_stop:\n        print(f\"Early stopping triggered after {epoch+1} epochs!\")\n        final_model_path = os.path.join(checkpoint_dir, 'BratsCV_final.pt')\n        torch.save(model, final_model_path)\n        api.upload_file(\n            path_or_fileobj=final_model_path,\n            path_in_repo=\"BratsCV_final.pt\",\n            repo_id=repo_name,\n            token=hf_token\n        )\n        print(\"Final model uploaded to Hugging Face!\")\n        break\n\n    # Free memory after each epoch\n    torch.cuda.empty_cache()\n\n# Plot training and validation metrics\nplt.figure(figsize=(15, 5))\n\nplt.subplot(1, 3, 1)\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.title('Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 3, 2)\nplt.plot(train_dice_scores, label='Train Dice')\nplt.plot(val_dice_scores, label='Validation Dice')\nplt.title('Dice Score')\nplt.xlabel('Epoch')\nplt.ylabel('Dice')\nplt.legend()\n\nplt.subplot(1, 3, 3)\nplt.plot(learning_rates)\nplt.title('Learning Rate')\nplt.xlabel('Epoch')\nplt.ylabel('LR')\n\nplt.tight_layout()\nplt.savefig('training_metrics.png')\nplt.show()\n\nprint(f\"Training completed! Best validation Dice score: {best_val_dice:.4f}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":442},"id":"tvBKokUoSFQc","outputId":"24f46f40-bb20-4cf6-c376-cb7260f88118","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training (from restored model)","metadata":{"id":"A9GdedRxU8lv"}},{"cell_type":"code","source":"# Nome del checkpoint da recuperare\ncheckpoint_filename = \"checkpoints/BratsCV_epoch_120.pt\"\nrepo_name = \"dugoalberto/3D_U_Net\"\nlocal_checkpoint_path = api.hf_hub_download(\n        repo_id=repo_name,\n        filename=checkpoint_filename,\n        token=hf_token\n)\ncheckpoint = torch.load(local_checkpoint_path)\n\n# Verifica i parametri recuperati\nprint(\"Checkpoint Recovery Information:\")\nprint(\"-\" * 40)\n\n# Stampa informazioni sull'epoch\nprint(f\"Epoch: {checkpoint.get('epoch', 'Not found')}\")\n\n# Stampa metriche\nprint(f\"Training Loss: {checkpoint.get('train_loss', 'Not found')}\")\nprint(f\"Validation Loss: {checkpoint.get('val_loss', 'Not found')}\")\nprint(f\"Training Dice Score: {checkpoint.get('train_dice', 'Not found')}\")\nprint(f\"Validation Dice Score: {checkpoint.get('val_dice', 'Not found')}\")\nprint(f\"Best Validation Dice Score: {checkpoint.get('best_val_dice', 'Not found')}\")\n\nmodel = ImprovedUNet3D()\nmodel = torch.nn.DataParallel(model)\nmodel.load_state_dict(checkpoint['model_state_dict'])\nmodel.to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":188,"referenced_widgets":["4d33e2acac44408bbaec22cd12087d4b","c547671ecdee43538c4e0b125169a84f","ee904822cfb4460db7725590b50992b9","3a85e48858b04398bd73c770f2cd79ef","6ec5667f949546f19e938b801dc6454e","9d7b2a9c3b8c4e6597ace70ca37faa0f","8d37c15c27b14da69d99a11abb5632a0","84f93c59f03a45bfadf277cdb4cd6226","1485ba524e2d48cc95f0872593022113","b316a62934844a6dac2d14796ae781f4","79940d98186349e7b1a2b6164c059c82"]},"id":"3tWiI6eHYZDg","outputId":"76852b2a-b960-4d72-8622-cbdb4f664346","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T17:40:42.051036Z","iopub.execute_input":"2025-07-01T17:40:42.051317Z","iopub.status.idle":"2025-07-01T17:40:42.162487Z","shell.execute_reply.started":"2025-07-01T17:40:42.051297Z","shell.execute_reply":"2025-07-01T17:40:42.161746Z"}},"outputs":[{"name":"stdout","text":"Checkpoint Recovery Information:\n----------------------------------------\nEpoch: 120\nTraining Loss: 0.19613416381433707\nValidation Loss: 0.2129683260982101\nTraining Dice Score: 0.8485563746114977\nValidation Dice Score: 0.787887025121096\nBest Validation Dice Score: 0.7913068532943726\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/3430020675.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(local_checkpoint_path)\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"DataParallel(\n  (module): ImprovedUNet3D(\n    (enc1): Sequential(\n      (0): Conv3d(4, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n      (1): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n      (3): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n      (4): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n    )\n    (pool1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (enc2): Sequential(\n      (0): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n      (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n      (3): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n      (4): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n    )\n    (pool2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (enc3): Sequential(\n      (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n      (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n      (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n      (4): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n    )\n    (upconv2): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n    (dec2): Sequential(\n      (0): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n      (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n      (3): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n      (4): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n    )\n    (upconv1): ConvTranspose3d(32, 16, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n    (dec1): Sequential(\n      (0): Conv3d(32, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n      (1): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n      (3): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n      (4): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n    )\n    (dropout): Dropout3d(p=0.1, inplace=False)\n    (final_conv): Conv3d(16, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n  )\n)"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"optimizer = optim.AdamW(model.parameters(), lr=0.00004, weight_decay=5e-6)\n#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n#scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=1e-6)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer,\n    mode='max',           # 'max' because we want to maximize validation accuracy\n    factor=0.8,           # Multiply LR by this factor when reducing\n    patience=2,           # Number of epochs with no improvement after which LR will be reduced\n    verbose=True,         # Print message when LR is reduced\n    threshold=0.1,      # Threshold for measuring improvement\n    min_lr=1e-9           # Lower bound on the learning rate\n)\n\nnum_epochs = 300  # Increased epochs with early stopping\nstart_epoch = checkpoint['epoch']\nearly_stopping = EarlyStopping(patience=10)\nuse_amp = True\nscaler = torch.cuda.amp.GradScaler(enabled=use_amp)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2IGF9_-vU99F","outputId":"99eec821-4f0d-49e6-b88c-b9f3b476ac31","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T17:40:48.973219Z","iopub.execute_input":"2025-07-01T17:40:48.973495Z","iopub.status.idle":"2025-07-01T17:40:48.986269Z","shell.execute_reply.started":"2025-07-01T17:40:48.973474Z","shell.execute_reply":"2025-07-01T17:40:48.985514Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n/tmp/ipykernel_31/603968276.py:18: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Lists to store metrics\ntrain_losses = []\nval_losses = []\ntrain_dice_scores = []\nval_dice_scores = []\nlearning_rates = []\n\nbest_val_dice = checkpoint['best_val_dice']\n\n# Restart the training\nfor epoch in range(start_epoch, num_epochs):\n    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n    # Train\n    train_loss, train_dice = train_one_epoch(model, train_loader, optimizer, criterion, device, scaler)\n    train_losses.append(train_loss)\n    train_dice_scores.append(train_dice)\n\n    # Free memory before validation\n    torch.cuda.empty_cache()\n\n    # Validate\n    val_loss, val_dice = validate_one_epoch(model, val_loader, criterion, device)\n    val_losses.append(val_loss)\n    val_dice_scores.append(val_dice)\n    \n    # Update learning rate\n    current_lr = optimizer.param_groups[0]['lr']\n    print(current_lr)\n    learning_rates.append(current_lr)\n    if scheduler is not None and isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n            scheduler.step(val_loss)\n    else :\n        scheduler.step()\n    #torch.cuda.empty_cache()\n    # Print epoch results\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Dice: {train_dice:.4f}\")\n    print(f\"Validation Loss: {val_loss:.4f}, Validation Dice: {val_dice:.4f}\")\n\n    if val_dice > best_val_dice:\n        best_val_dice = val_dice\n        best_model_path = os.path.join(checkpoint_dir, 'BratsCV_best.pt')\n        torch.save(model, best_model_path)\n        print(f\"Best model saved with Dice score: {best_val_dice:.4f}!\")\n        api.upload_file(\n            path_or_fileobj=best_model_path,\n            path_in_repo=\"BratsCV_best.pt\",\n            repo_id=repo_name,\n            token=hf_token\n        )\n        print(f\"Best model uploaded to Hugging Face!\")\n    if (epoch + 1) % 5 == 0 or epoch == num_epochs - 1:\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        checkpoint_path = os.path.join(checkpoint_dir, f'BratsCV_epoch_{epoch+1}_{timestamp}.pt')\n\n        # Save model state dictionary and optimizer state\n        checkpoint = {\n            'epoch': epoch + 1,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n            'train_loss': train_loss,\n            'val_loss': val_loss,\n            'train_dice': train_dice,\n            'val_dice': val_dice,\n            'best_val_dice': best_val_dice,\n            'learning_rate': current_lr\n        }\n        torch.save(checkpoint, checkpoint_path)\n\n        # Upload checkpoint to Hugging Face\n        try:\n            api.upload_file(\n                path_or_fileobj=checkpoint_path,\n                path_in_repo=f\"checkpoints/BratsCV_epoch_{epoch+1}.pt\",\n                repo_id=repo_name,\n                token=hf_token\n            )\n            print(f\"Checkpoint for epoch {epoch+1} uploaded to Hugging Face!\")\n        except Exception as e:\n            print(f\"Error uploading checkpoint to Hugging Face: {e}\")\n\n    # Check for early stopping\n    early_stopping(val_loss)\n    if early_stopping.early_stop:\n        print(f\"Early stopping triggered after {epoch+1} epochs!\")\n\n        # Save final model after early stopping\n        final_model_path = os.path.join(checkpoint_dir, 'BratsCV_final.pt')\n        torch.save(model, final_model_path)\n\n        # Upload final model to Hugging Face\n        api.upload_file(\n            path_or_fileobj=final_model_path,\n            path_in_repo=\"BratsCV_final.pt\",\n            repo_id=repo_name,\n            token=hf_token\n        )\n        print(\"Final model uploaded to Hugging Face!\")\n        break","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c1db8fd726df48d4a26bf2f7cab9ea33","3b8d6460771547d397adabb40db58016","6cd65914eed846e4a84c9e008d5354e2","fad750b9adb548369af2ec7d0b75d267","6cd2a21390c54dce826d5c0c1bdd90ca","39f6ea6f3d604ad195a7abf96142a672","7142cbf7d6f84abe94dc9467a2e20aee","423ea92d3f764b31b5cc9517a0b34494","f770dcc71e9d4263a1d25a0150869663","b10f2729cb0a458fa5ff2c7d859ab724","29332ea751b746a98098a4782ab837ef","35be443e8c3a4ea1a3211ee25da8f669","e0c787d4ca664b25a13b6bd06322aa4b","8038ac8f6df742868be37cdfce377620","e4fd195805604064950f941d03b9c50a","7751f31624d34e45b7656f4ecad497ba","955965f1854142f78ccd727edc0c36f5","aba02c8406f241fca6a0196757273ad7","4579438d457d4ae298fceef22c4f215e","66aff2997480405a8b1fcd89dfe8e649","c9ea97383ac845c1aa0c6b151262f4f0","7ff92b0a76814a68ad728b489acfed39","b4f78045b2e84f2f83beae7fc3aa3082","e47827be604c42b6b78a148ab663a09a","d64dd359c027474a98eefa022738bf92","d81836cff24e488d946f14b39258461a","76bb710b89e84c7a96a3aa413c516121","48a92b6ea58148eea8beac5634e68697","a7b46608184b46a2821b730845144cdd","b393678815784cc08989ea57d828c4b9","bbf566158f134821953f2054253cb9de","6dd43c5befe84bbabb535c93ffe9a98b","379cf7850a6d4b2c8a7b2b7f9e25295e","9152c09ce22242e199333fadab088c5e","e70fb89cf5bb40d7a801b9d8c6d10cc7","334ac583728545e4bb53c5907b03cab2","d15734cd3c434038b5779135ae20dae2","b4b8230f99a14d4894ff5dadedeba129","8a19294166874dd69ed87ab28deaf79b","759a9641cd234af282fd13a4c308b378","552269a2e190488b8c5ccbd111b27d2e","a6f5587506574aebb064896706609a9c","aa0e91ef105440218493c8683157abd4","ad80a1872a934874821b072973b95a4d","46b3e77478514273b87f91cd2e7acda6","e8aaac2b86034c29a52ed5f6c2071d13","c5fe4eeb165143fcbd692c7ca621b1e3","423134a8c93d44bfa19a10b16aac7078","ac678d71eafb41749553bccca9839954","85f3f262837749a0be0c36d8f6c01128","604cfe51c90b46a88b6b5d1c30db53d9","50fc3f2b3faf4d728e2add5c11cfc807","d2662596fb2740f597399556464db6ae","959fc1624d3f4bb5bbddde7fd4385b02","6dccbda6c7ac44778efdbac98b3e11c7"]},"id":"hJPAKLWNaAas","outputId":"c041559e-fb87-419b-dbff-72dae22dcd66","trusted":true},"outputs":[],"execution_count":null}]}