# -*- coding: utf-8 -*-
"""preProcessing

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/albertodugo2/preprocessing.7aca2753-7241-4757-b81a-9b247ad5f998.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250521/auto/storage/goog4_request%26X-Goog-Date%3D20250521T081006Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D070fa788e655d78ad7dac7448a11eb491faeaa324c5c9f1cd414a653d76eed3c729b2610a2f4f67836468180c640bfa1b2f3e1d0369b6608355b69b4dc9f559dddce97fba285e5cc06f975465eafb62a48dfe95465a44f0c8b3c1f99877c4b07addd888c8a6a39d64b32cddc6b2aef401655da76542ba8efdb538e5be1ba3a7d721f899c57cfe9d72e19b115b186a8011fad85f6d82425241edaab215d56f3aa9c736a53796f9fab6b83d2c8a84c42690a68241316f52e54aad7f94f807d4778abfe14b511e3a5d79df90c10b61165c47eb56d36711a7876ebcf8c984d64edde6994ac2143599e92e4f2247c1bb1b8fe40dbe1dedc12efbbddad76631fd78c76
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
awsaf49_brats20_dataset_training_validation_path = kagglehub.dataset_download('awsaf49/brats20-dataset-training-validation')

print('Data source import complete.')

import os
import torch
import logging

import sys
import random

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
from matplotlib import cm
import matplotlib.animation as anim
import matplotlib.patches as mpatches
import matplotlib.gridspec as gridspec


import nibabel as nib
import torch.nn as nn
import torch.optim as optim

import torch.nn.functional as F


from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix
from tqdm import tqdm


from torch.utils.data import Dataset, DataLoader, random_split
from torch.utils.tensorboard import SummaryWriter
from torch.cuda.amp import autocast, GradScaler
from sklearn.metrics import confusion_matrix

import cv2

"""## The network"""

class ImprovedUNet3D(nn.Module):
    def __init__(self, in_channels=4, out_channels=4, base_filters=16):
        super(ImprovedUNet3D, self).__init__()

        self.enc1 = self._make_layer(in_channels, base_filters)
        self.pool1 = nn.MaxPool3d(kernel_size=2, stride=2)

        self.enc2 = self._make_layer(base_filters, base_filters*2)
        self.pool2 = nn.MaxPool3d(kernel_size=2, stride=2)

        self.enc3 = self._make_layer(base_filters*2, base_filters*4)

        self.upconv2 = nn.ConvTranspose3d(base_filters*4, base_filters*2, kernel_size=2, stride=2)
        self.dec2 = self._make_layer(base_filters*4, base_filters*2)

        self.upconv1 = nn.ConvTranspose3d(base_filters*2, base_filters, kernel_size=2, stride=2)
        self.dec1 = self._make_layer(base_filters*2, base_filters)

        self.dropout = nn.Dropout3d(0.10)
        self.final_conv = nn.Conv3d(base_filters, out_channels, kernel_size=1)

        self._initialize_weights()

    def _make_layer(self, in_channels, out_channels):
        """Create a residual block"""
        return nn.Sequential(
            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.InstanceNorm3d(out_channels),
            nn.LeakyReLU(inplace=True),
            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.InstanceNorm3d(out_channels),
            nn.LeakyReLU(inplace=True)
        )

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv3d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.InstanceNorm3d):
                if m.weight is not None:
                    nn.init.constant_(m.weight, 1)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)

    def forward(self, x):
        enc1_out = self.enc1(x)
        p1 = self.pool1(enc1_out)

        enc2_out = self.enc2(p1)
        p2 = self.pool2(enc2_out)

        enc3_out = self.enc3(p2)

        up2 = self.upconv2(enc3_out)

        diffY = enc2_out.size()[2] - up2.size()[2]
        diffX = enc2_out.size()[3] - up2.size()[3]
        diffZ = enc2_out.size()[4] - up2.size()[4]

        up2 = F.pad(up2, [
            diffZ // 2, diffZ - diffZ // 2,
            diffX // 2, diffX - diffX // 2,
            diffY // 2, diffY - diffY // 2
        ])
        concat2 = torch.cat([up2, enc2_out], dim=1)
        dec2_out = self.dec2(concat2)

        up1 = self.upconv1(dec2_out)

        diffY = enc1_out.size()[2] - up1.size()[2]
        diffX = enc1_out.size()[3] - up1.size()[3]
        diffZ = enc1_out.size()[4] - up1.size()[4]

        up1 = F.pad(up1, [
            diffZ // 2, diffZ - diffZ // 2,
            diffX // 2, diffX - diffX // 2,
            diffY // 2, diffY - diffY // 2
        ])
        concat1 = torch.cat([up1, enc1_out], dim=1)
        dec1_out = self.dec1(concat1)

        x = self.dropout(dec1_out)

        out = self.final_conv(x)

        return out

model = ImprovedUNet3D(base_filters=32)
total_params = sum(p.numel() for p in model.parameters())
print(f"Total parameters: {total_params:,}")
size_in_bytes = total_params * 4
size_in_mb = size_in_bytes / (1024 ** 2)
print(f"Model size (inference): {size_in_mb:.2f} MB")

import kagglehub

# Download latest version
path = kagglehub.dataset_download("awsaf49/brats20-dataset-training-validation")
data_dir = path + "/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData"
train_dir = path + "/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData"
val_dir = path +"/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData"

"""##Â Dataset processing"""

class BrainTumorDataset(Dataset):

    def __init__(self, patient_list, data_dir, is_train=True, transform=None, slice_range=(60, 100)):
        self.data_dir = data_dir
        self.is_train = is_train
        self.transform = transform
        self.modalities = ["flair", "t1", "t1ce", "t2"]

        # Excluding Patient 355 (due to image problem)
        self.patients = [p for p in patient_list if not p.endswith(".csv") and "355" not in p]

        self.slice_range = slice_range  # Only load a range of slices to save memory

    def load_nifti(self, path):
        nifti_img = nib.load(path)
        return np.array(nifti_img.get_fdata(), dtype=np.float32)

    def __len__(self):
        return len(self.patients)

    def __getitem__(self, idx):
        patient_id = self.patients[idx]

        # Excluding Patient 355 (again)
        if patient_id == "BraTS20_Training_355":
            return None

        patient_path = os.path.join(self.data_dir, patient_id)

        # Load 4 MR modalities
        images = []
        #rememeber that modalities has ["flair", "t1", "t1ce", "t2"]
        for modality in self.modalities:
            img_path = os.path.join(patient_path, f"{patient_id}_{modality}.nii")
            img = self.load_nifti(img_path)

            # Only keep the central axial slices where tumor is most likely to be visible
            start_slice, end_slice = self.slice_range
            img = img[:, :, start_slice:end_slice]

            # Z-score normalization for better stability
            if np.std(img) > 0:
                img = (img - np.mean(img)) / np.std(img)
            else:
                img = np.zeros_like(img)

            images.append(img)

        # Stack images as channels
        images = np.stack(images, axis=0)  # (4, H, W, D_reduced)

        # If it is a train_set load segmentation mask too
        if self.is_train:
            # Try multiple possible segmentation file names
            seg_paths = [
                os.path.join(patient_path, f"{patient_id}_seg.nii"),
                os.path.join(patient_path, f"{patient_id}_Segm.nii"),
                os.path.join(patient_path, f"{patient_id}_Segmentation.nii")
            ]

            # Find the first existing segmentation file
            seg_path = next((path for path in seg_paths if os.path.exists(path)), None)

            if seg_path is None:
                print(f"Warning: No segmentation file found for patient {patient_id}.")
                mask = np.zeros_like(images[0], dtype=np.int64)  # Empty mask as numpy array
            else:
                mask = self.load_nifti(seg_path)

                # Get the same slice range
                mask = mask[:, :, self.slice_range[0]:self.slice_range[1]]

                # Convert labels
                mask[mask == 4] = 3  # Reassign label 4 to 3 (Enhancing Tumor)
        else:
            mask = None

        # Apply transformations on the numpy arrays before converting to tensors
        if self.transform is not None:
            if self.is_train:
                transformed = self.transform(image=images, mask=mask)
                images = transformed["image"]
                mask = transformed["mask"]
            else:
                transformed = self.transform(image=images)
                images = transformed["image"]

        # Convert to PyTorch tensors AFTER transformations
        if not isinstance(images, torch.Tensor):
            images = torch.tensor(images, dtype=torch.float32)

        if self.is_train and mask is not None:
            if not isinstance(mask, torch.Tensor):
                mask = torch.tensor(mask, dtype=torch.long)
            else:
                mask = mask.to(dtype=torch.long)

        return (images, mask) if self.is_train else images

# Optimize memory by selecting a subset of patients for quick testing
def get_subset_patients(patient_list, ratio=0.3):
    """Get a subset of patients for memory-efficient training"""
    n_patients = max(2, int(len(patient_list) * ratio))
    return random.sample(patient_list, n_patients)

def visualize_samples_with_colors(data_dir, BraTS20_Training_00n):
    flair = data_dir+ BraTS20_Training_00n + BraTS20_Training_00n +'_flair.nii'
    mask = data_dir+ BraTS20_Training_00n + BraTS20_Training_00n +'_seg.nii'
    t1 = data_dir+ BraTS20_Training_00n + BraTS20_Training_00n +'_t1.nii'
    t2 = data_dir+ BraTS20_Training_00n + BraTS20_Training_00n +'_t2.nii'
    t1ce = data_dir+ BraTS20_Training_00n + BraTS20_Training_00n +'_t1ce.nii'

    flair_img = nib.load(flair)
    flair_img = np.asanyarray(flair_img.dataobj)
    flair_img = np.rot90(flair_img)

    sample_mask = nib.load(mask)
    sample_mask = np.asanyarray(sample_mask.dataobj)
    sample_mask = np.rot90(sample_mask)

    t1_img = nib.load(t1)
    t1_img = np.asanyarray(t1_img.dataobj)
    t1_img  = np.rot90(t1_img)

    t2_img = nib.load(t2)
    t2_img = np.asanyarray(t2_img.dataobj)
    t2_img  = np.rot90(t2_img)

    t1ce_img = nib.load(t1ce)
    t1ce_img = np.asanyarray(t1ce_img.dataobj)
    t1ce_img  = np.rot90(t1ce_img)

    mask_WT = sample_mask.copy()
    mask_WT[mask_WT == 1] = 1
    mask_WT[mask_WT == 2] = 1
    mask_WT[mask_WT == 4] = 1

    mask_TC = sample_mask.copy()
    mask_TC[mask_TC == 1] = 1
    mask_TC[mask_TC == 2] = 0
    mask_TC[mask_TC == 4] = 1

    mask_ET = sample_mask.copy()
    mask_ET[mask_ET == 1] = 0
    mask_ET[mask_ET == 2] = 0
    mask_ET[mask_ET == 4] = 1

    fig = plt.figure(figsize=(20, 10))

    gs = gridspec.GridSpec(nrows=2, ncols=5, height_ratios=[1, 1.5])

    fontsize = 10
    #  Varying density along a streamline
    ax0 = fig.add_subplot(gs[0, 0])
    flair = ax0.imshow(flair_img[:,:,65], cmap='bone')
    ax0.set_title("FLAIR", fontsize = fontsize, weight='bold', y=-0.2)
    fig.colorbar(flair)

    #  Varying density along a streamline
    ax1 = fig.add_subplot(gs[0, 1])
    t1 = ax1.imshow(t1_img[:,:,65], cmap='bone')
    ax1.set_title("T1", fontsize = fontsize, weight='bold', y=-0.2)
    fig.colorbar(t1)

    #  Varying density along a streamline
    ax2 = fig.add_subplot(gs[0, 2])
    t2 = ax2.imshow(t2_img[:,:,65], cmap='bone')
    ax2.set_title("T2", fontsize = fontsize, weight='bold', y=-0.2)
    fig.colorbar(t2)

    #  Varying density along a streamline
    ax3 = fig.add_subplot(gs[0, 3])
    t1ce = ax3.imshow(t1ce_img[:,:,65], cmap='bone')
    ax3.set_title("T1 contrast", fontsize = fontsize, weight='bold', y=-0.2)
    fig.colorbar(t1ce)

        #  Varying density along a streamline
    ax4 = fig.add_subplot(gs[1, 1:3])

    #ax4.imshow(np.ma.masked_where(mask_WT[:,:,65]== False,  mask_WT[:,:,65]), cmap='summer', alpha=0.6)
    l1 = ax4.imshow(mask_WT[:,:,65], cmap='summer',)
    l2 = ax4.imshow(np.ma.masked_where(mask_TC[:,:,65]== False,  mask_TC[:,:,65]), cmap='rainbow', alpha=0.6)
    l3 = ax4.imshow(np.ma.masked_where(mask_ET[:,:,65] == False, mask_ET[:,:,65]), cmap='winter', alpha=0.6)

    ax4.set_title("", fontsize=fontsize, weight='bold', y=-0.1)

    _ = [ax.set_axis_off() for ax in [ax0,ax1,ax2,ax3, ax4]]

    colors = [im.cmap(im.norm(1)) for im in [l1,l2, l3]]
    labels = ['Non-Enhancing tumor core', 'Peritumoral Edema ', 'GD-enhancing tumor']
    patches = [ mpatches.Patch(color=colors[i], label=f"{labels[i]}") for i in range(len(labels))]
    # put those patched as legend-handles into the legend
    plt.legend(handles=patches, bbox_to_anchor=(1.1, 0.65), loc=2, borderaxespad=0.4,fontsize = 'xx-large',
              title='Mask Labels', title_fontsize=18, edgecolor="black",  facecolor='#c5c6c7')

    plt.suptitle("Multimodal Scans -  Data | Manually-segmented mask - Target", fontsize=20, weight='bold')

    fig.savefig("data_sample.png", format="png",  pad_inches=0.2, transparent=False, bbox_inches='tight')
    fig.savefig("data_sample.svg", format="svg",  pad_inches=0.2, transparent=False, bbox_inches='tight')

"""## Dataset splitting and processing

"""

from torch.utils.data import ConcatDataset

# Get patient directories
train_patient_dirs = os.listdir(train_dir)
test_patient_dirs = os.listdir(val_dir)

# Filter only valid directories (patients)
all_train_patients = []
for p in train_patient_dirs:
    if os.path.isdir(os.path.join(train_dir, p)):
        all_train_patients.append(p)
all_train_patients.sort()

all_test_patients = []
for p in test_patient_dirs:
    if os.path.isdir(os.path.join(val_dir, p)):
        all_test_patients.append(p)
all_test_patients.sort()


slice_range = (0, 155)
slice_range = (0, 155)
train_patients, val_patients = train_test_split(all_train_patients, test_size=0.2, random_state=42)
train_dataset = BrainTumorDataset(
    patient_list=train_patients,
    data_dir=train_dir,
    slice_range=slice_range,
    transform=None
)

val_dataset = BrainTumorDataset(
    patient_list=val_patients,
    data_dir=train_dir,
    slice_range=slice_range
)

test_dataset = BrainTumorDataset(
    patient_list=all_test_patients,
    data_dir=val_dir,
    is_train=False,
    slice_range=slice_range
)
print(f"Using {len(train_dataset)} training patients and {len(val_dataset)} test patients")

# DataLoaders with small batch_size but more workers if available
train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2)
val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=2)

# Check sample data dimensions
sample_img, sample_mask = next(iter(train_loader))
print(f"Train set image dimension: {sample_img.shape}")  # Should be smaller now
print(f"Train set segmentation dimension: {sample_mask.shape}")

sample_img, sample_mask = next(iter(val_loader))
print("Validation set image dimension:", sample_img.shape)
print("Validation set segmentation dimension:", sample_mask.shape)

sample_img = next(iter(test_loader))
print("Test set image dimension:", sample_img.shape)

"""## set devices and deal with them"""

import gc
import torch

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

if torch.cuda.is_available():
    torch.cuda.empty_cache()
    gc.collect()
    for i in range(5):
        gc.collect()
        torch.cuda.empty_cache()

    num_gpus = torch.cuda.device_count()
    print(f"Using {num_gpus} GPUs for training." if num_gpus > 1 else
          f"Using {torch.cuda.get_device_name(0)} for training.")

    # Print available and total memory
    if hasattr(torch.cuda, 'get_device_properties'):
        for i in range(num_gpus):
            prop = torch.cuda.get_device_properties(i)
            print(f"GPU {i}: {prop.name}")
            print(f"  Total memory: {prop.total_memory / 1024**3:.2f} GB")
            print(f"  Available memory: {torch.cuda.memory_reserved(i) / 1024**3:.2f} GB reserved")
            print(f"  Allocated memory: {torch.cuda.memory_allocated(i) / 1024**3:.2f} GB")
else:
    print("Using CPU for training.")

model = ImprovedUNet3D(base_filters=32)
model = torch.nn.DataParallel(model)
model.to(device)

def dice_coefficient_soft(pred_probs, target, num_classes=4, smooth=1e-6):
    dice_scores = []
    target_one_hot = F.one_hot(target, num_classes=num_classes).permute(0, 4, 1, 2, 3).float()
    for class_id in range(num_classes):
        pred_class = pred_probs[:, class_id, ...]
        target_class = target_one_hot[:, class_id, ...]
        intersection = (pred_class * target_class).sum(dim=[1, 2, 3]) # Sum over spatial dims
        pred_sum = pred_class.sum(dim=[1, 2, 3])
        target_sum = target_class.sum(dim=[1, 2, 3])
        dice_score_class = (2. * intersection + smooth) / (pred_sum + target_sum + smooth)
        dice_scores.append(dice_score_class.mean())
    dice_scores = torch.stack(dice_scores)
    return dice_scores.mean()

# Modified DiceLoss using Soft Dice
class DiceLoss(nn.Module):
    def __init__(self, num_classes=4, smooth=1e-6):
        super(DiceLoss, self).__init__()
        self.num_classes = num_classes
        self.smooth = smooth

    def forward(self, y_pred_logits, y_true):
        y_pred_probs = F.softmax(y_pred_logits, dim=1)
        dice = dice_coefficient_soft(y_pred_probs, y_true, num_classes=self.num_classes, smooth=self.smooth)
        return 1 - dice

class CombinedLoss(nn.Module):
    def __init__(self, weight_dice=0.7, weight_ce=0.3, num_classes=4):
        super(CombinedLoss, self).__init__()
        self.weight_dice = weight_dice
        self.weight_ce = weight_ce
        self.dice_loss = DiceLoss(num_classes=num_classes)
        self.ce_loss = nn.CrossEntropyLoss()

    def forward(self, inputs_logits, targets):
        ce_loss_value = self.ce_loss(inputs_logits, targets)
        dice_loss_value = self.dice_loss(inputs_logits, targets)
        return self.weight_ce * ce_loss_value + self.weight_dice * dice_loss_value

def dice_coefficient_metric(pred_labels, target_labels, num_classes=4, smooth=1e-6):
    dice_scores = []
    for class_id in range(num_classes):
        pred_class = (pred_labels == class_id).float()
        target_class = (target_labels == class_id).float()
        intersection = (pred_class * target_class).sum()
        dice_score = (2. * intersection + smooth) / (pred_class.sum() + target_class.sum() + smooth)
        dice_scores.append(dice_score)
    dice_scores = torch.stack(dice_scores)
    return dice_scores.mean()

# Initialize model with improved architecture
model = ImprovedUNet3D(in_channels=4, out_channels=4, base_filters=16)
model = torch.nn.DataParallel(model)
model.to(device)
# Use mixed precision for memory efficiency
use_amp = True
scaler = torch.amp.GradScaler("cuda", enabled="use_amp")
criterion = CombinedLoss()
optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=5e-3)
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=1e-6)

# Function to train for one epoch with memory optimization
def train_one_epoch(model, dataloader, optimizer, criterion, device, scaler=None):
    use_amp = scaler is not None
    model.train()
    epoch_loss = 0.0
    dice_score = 0.0
    dice_per_class = torch.zeros(4, device=device)
    batch_count = 0
    for i, (inputs, targets) in enumerate(dataloader):
        inputs = inputs.to(device)
        targets = targets.to(device)
        optimizer.zero_grad()
        if use_amp:
            with torch.amp.autocast(device_type='cuda', enabled=True):
                outputs = model(inputs)
                loss = criterion(outputs, targets)
            scaler.scale(loss).backward()
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.5)
            scaler.step(optimizer)
            scaler.update()
        else:
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.5)
            optimizer.step()
        epoch_loss += loss.item()
        # Predictions
        if outputs.shape[1] > 1:
            _, preds = torch.max(outputs, 1)
        else:
            preds = (torch.sigmoid(outputs) > 0.5).float()

        # Calcola il dice score complessivo
        dice = dice_coefficient_metric(preds, targets)
        dice_score += dice.item()

        # Calcola il dice score per ogni classe
        class_dice_scores = []
        for class_id in range(4):
            pred_class = (preds == class_id).float()
            target_class = (targets == class_id).float()
            intersection = (pred_class * target_class).sum()
            class_dice = (2. * intersection + 1e-6) / (pred_class.sum() + target_class.sum() + 1e-6)
            dice_per_class[class_id] += class_dice.item()
            class_dice_scores.append(class_dice.item())

        batch_count += 1
        if (i + 1) % 5 == 0:
            print(f"Batch {i+1}/{len(dataloader)}, Loss: {loss.item():.4f}, Dice: {dice:.4f}")
            print(f"  Class Dice: Background: {class_dice_scores[0]:.4f}, NCR: {class_dice_scores[1]:.4f}, ED: {class_dice_scores[2]:.4f}, ET: {class_dice_scores[3]:.4f}")

        del inputs, targets, outputs, preds
        torch.cuda.empty_cache()

    avg_loss = epoch_loss / batch_count
    avg_dice = dice_score / batch_count
    avg_dice_per_class = dice_per_class / batch_count

    return avg_loss, avg_dice, avg_dice_per_class

# Validation loop
def validate_one_epoch(model, dataloader, criterion, device):
    model.eval()
    epoch_loss = 0.0
    dice_score = 0.0
    dice_per_class = torch.zeros(4, device=device)
    batch_count = 0

    with torch.no_grad():
        for i, (inputs, targets) in enumerate(dataloader):
            inputs = inputs.to(device)
            targets = targets.to(device)
            # Forward pass
            if isinstance(criterion, CombinedLoss) and hasattr(criterion, 'dice_loss') and hasattr(criterion.dice_loss, 'num_classes'):
                num_classes = criterion.dice_loss.num_classes
            else:
                num_classes = 4  # Default value

            with torch.cuda.amp.autocast(enabled=scaler is not None):
                outputs = model(inputs) # Logits
                loss = criterion(outputs, targets) # Uses CombinedLoss with SoftDice

            epoch_loss += loss.item()
            if outputs.shape[1] > 1:
                _, preds = torch.max(outputs, 1) # Get integer class labels for metric
            else:
                preds = (torch.sigmoid(outputs) > 0.5).float() # For binary case

            # Calcola il dice score complessivo
            dice = dice_coefficient_metric(preds, targets, num_classes=num_classes)
            dice_score += dice.item()

            # Calcola il dice score per ogni classe
            for class_id in range(num_classes):
                pred_class = (preds == class_id).float()
                target_class = (targets == class_id).float()
                intersection = (pred_class * target_class).sum()
                class_dice = (2. * intersection + 1e-6) / (pred_class.sum() + target_class.sum() + 1e-6)
                dice_per_class[class_id] += class_dice.item()

            batch_count += 1
            # Free up memory
            del inputs, targets, outputs, preds
            torch.cuda.empty_cache()

    # Calculate average metrics
    avg_loss = epoch_loss / batch_count
    avg_dice = dice_score / batch_count
    avg_dice_per_class = dice_per_class / batch_count

    return avg_loss, avg_dice, avg_dice_per_class

# Early stopping implementation
class EarlyStopping:
    def __init__(self, patience=7, min_delta=0.001):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_score = None
        self.early_stop = False

    def __call__(self, val_loss):
        if self.best_score is None:
            self.best_score = val_loss
        elif val_loss > self.best_score + self.min_delta:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = val_loss
            self.counter = 0

from huggingface_hub import HfApi, create_repo
import os
from datetime import datetime
from kaggle_secrets import UserSecretsClient
user_secrets = UserSecretsClient()
hf_token = user_secrets.get_secret("HF_TOKEN")
api = HfApi()
repo_name = "dugoalberto/3dFullSlice4mbFocalLoss"
checkpoint_dir = "./checkpoints"
os.makedirs(checkpoint_dir, exist_ok=True)

"""## Training (from new model)"""

# Training loop with early stopping
num_epochs = 150  # Increased epochs with early stopping
best_val_dice = 0.0
early_stopping = EarlyStopping(patience=10)

# Lists to store metrics
train_losses = []
val_losses = []
train_dice_scores = []
val_dice_scores = []
learning_rates = []

for epoch in range(num_epochs):
    print(f"Epoch [{epoch+1}/{num_epochs}]")

    # Train
    train_loss, train_dice = train_one_epoch(model, train_loader, optimizer, criterion, device, scaler)
    train_losses.append(train_loss)
    train_dice_scores.append(train_dice)

    # Update learning rate
    current_lr = optimizer.param_groups[0]['lr']
    learning_rates.append(current_lr)
    if scheduler is not None and isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):
            scheduler.step(val_loss)
    else:
        scheduler.step()

    # Free memory before validation
    torch.cuda.empty_cache()

    # Validate
    val_loss, val_dice = validate_one_epoch(model, val_loader, criterion, device)
    val_losses.append(val_loss)
    val_dice_scores.append(val_dice)

    # Print epoch results
    print(f"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Dice: {train_dice:.4f}")
    print(f"Validation Loss: {val_loss:.4f}, Validation Dice: {val_dice:.4f}, LR: {current_lr:.6f}")

    if val_dice > best_val_dice:
        best_val_dice = val_dice
        best_model_path = os.path.join(checkpoint_dir, 'BratsCV_best.pt')
        torch.save(model, best_model_path)
        print(f"Best model saved with Dice score: {best_val_dice:.4f}!")

        # Upload best model to Hugging Face
        api.upload_file(
            path_or_fileobj=best_model_path,
            path_in_repo="BratsCV_best.pt",
            repo_id=repo_name,
            token=hf_token
        )
        print(f"Best model uploaded to Hugging Face!")

    # Save regular checkpoint every 5 epochs or final epoch
    if (epoch + 1) % 5 == 0 or epoch == num_epochs - 1:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        checkpoint_path = os.path.join(checkpoint_dir, f'BratsCV_epoch_{epoch+1}_{timestamp}.pt')

        # Save model state dictionary and optimizer state
        checkpoint = {
            'epoch': epoch + 1,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,
            'train_loss': train_loss,
            'val_loss': val_loss,
            'train_dice': train_dice,
            'val_dice': val_dice,
            'best_val_dice': best_val_dice,
            'learning_rate': current_lr
        }
        torch.save(checkpoint, checkpoint_path)

        # Upload checkpoint to Hugging Face
        try:
            api.upload_file(
                path_or_fileobj=checkpoint_path,
                path_in_repo=f"checkpoints/BratsCV_epoch_{epoch+1}.pt",
                repo_id=repo_name,
                token=hf_token
            )
            print(f"Checkpoint for epoch {epoch+1} uploaded to Hugging Face!")
        except Exception as e:
            print(f"Error uploading checkpoint to Hugging Face: {e}")

    early_stopping(val_loss)
    if early_stopping.early_stop:
        print(f"Early stopping triggered after {epoch+1} epochs!")
        final_model_path = os.path.join(checkpoint_dir, 'BratsCV_final.pt')
        torch.save(model, final_model_path)
        api.upload_file(
            path_or_fileobj=final_model_path,
            path_in_repo="BratsCV_final.pt",
            repo_id=repo_name,
            token=hf_token
        )
        print("Final model uploaded to Hugging Face!")
        break

    # Free memory after each epoch
    torch.cuda.empty_cache()

# Plot training and validation metrics
plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Validation Loss')
plt.title('Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 3, 2)
plt.plot(train_dice_scores, label='Train Dice')
plt.plot(val_dice_scores, label='Validation Dice')
plt.title('Dice Score')
plt.xlabel('Epoch')
plt.ylabel('Dice')
plt.legend()

plt.subplot(1, 3, 3)
plt.plot(learning_rates)
plt.title('Learning Rate')
plt.xlabel('Epoch')
plt.ylabel('LR')

plt.tight_layout()
plt.savefig('training_metrics.png')
plt.show()

print(f"Training completed! Best validation Dice score: {best_val_dice:.4f}")

"""## Training (from restored model)"""

# Nome del checkpoint da recuperare
checkpoint_filename = "checkpoints/BratsCV_epoch_120.pt"
repo_name = "dugoalberto/3D_U_Net_full_slice"
local_checkpoint_path = api.hf_hub_download(
        repo_id=repo_name,
        filename=checkpoint_filename,
        token=hf_token
)
checkpoint = torch.load(local_checkpoint_path)

# Verifica i parametri recuperati
print("Checkpoint Recovery Information:")
print("-" * 40)

# Stampa informazioni sull'epoch
print(f"Epoch: {checkpoint.get('epoch', 'Not found')}")

# Stampa metriche
print(f"Training Loss: {checkpoint.get('train_loss', 'Not found')}")
print(f"Validation Loss: {checkpoint.get('val_loss', 'Not found')}")
print(f"Training Dice Score: {checkpoint.get('train_dice', 'Not found')}")
print(f"Validation Dice Score: {checkpoint.get('val_dice', 'Not found')}")
print(f"Best Validation Dice Score: {checkpoint.get('best_val_dice', 'Not found')}")

# Verifica i parametri recuperati
#model = ImprovedUNet3D(in_channels=4, out_channels=4, base_filters=32, dropout_rate=0.2).to(device)
model = ImprovedUNet3D()
model = torch.nn.DataParallel(model)
model.load_state_dict(checkpoint['model_state_dict'])
model.to(device)
#criterion = FocalLoss(alpha=torch.tensor([0.05, 0.2, 0.2, 0.55]).to(device), gamma=2.0)

# Ricreate the parameters fro the fetched model
optimizer = optim.AdamW(model.parameters(), lr=0.00004, weight_decay=5e-6)
#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
#scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=1e-6)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimizer,
    mode='max',           # 'max' because we want to maximize validation accuracy
    factor=0.8,           # Multiply LR by this factor when reducing
    patience=2,           # Number of epochs with no improvement after which LR will be reduced
    verbose=True,         # Print message when LR is reduced
    threshold=0.1,      # Threshold for measuring improvement
    min_lr=1e-9           # Lower bound on the learning rate
)

num_epochs = 300  # Increased epochs with early stopping
start_epoch = checkpoint['epoch']
early_stopping = EarlyStopping(patience=10)
use_amp = True
scaler = torch.cuda.amp.GradScaler(enabled=use_amp)

# Lists to store metrics
train_losses = []
val_losses = []
train_dice_scores = []
val_dice_scores = []
learning_rates = []

best_val_dice = checkpoint['best_val_dice']

# Restart the training
for epoch in range(start_epoch, num_epochs):
    print(f"Epoch [{epoch+1}/{num_epochs}]")
    # Train
    train_loss, train_dice = train_one_epoch(model, train_loader, optimizer, criterion, device, scaler)
    train_losses.append(train_loss)
    train_dice_scores.append(train_dice)

    # Free memory before validation
    torch.cuda.empty_cache()

    # Validate
    val_loss, val_dice = validate_one_epoch(model, val_loader, criterion, device)
    val_losses.append(val_loss)
    val_dice_scores.append(val_dice)

    # Update learning rate
    current_lr = optimizer.param_groups[0]['lr']
    print(current_lr)
    learning_rates.append(current_lr)
    if scheduler is not None and isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):
            scheduler.step(val_loss)
    else :
        scheduler.step()
    #torch.cuda.empty_cache()
    # Print epoch results
    print(f"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Dice: {train_dice:.4f}")
    print(f"Validation Loss: {val_loss:.4f}, Validation Dice: {val_dice:.4f}")

    if val_dice > best_val_dice:
        best_val_dice = val_dice
        best_model_path = os.path.join(checkpoint_dir, 'BratsCV_best.pt')
        torch.save(model, best_model_path)
        print(f"Best model saved with Dice score: {best_val_dice:.4f}!")

        # Upload best model to Hugging Face
        api.upload_file(
            path_or_fileobj=best_model_path,
            path_in_repo="BratsCV_best.pt",
            repo_id=repo_name,
            token=hf_token
        )
        print(f"Best model uploaded to Hugging Face!")

    # Save regular checkpoint every 5 epochs or final epoch
    if (epoch + 1) % 5 == 0 or epoch == num_epochs - 1:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        checkpoint_path = os.path.join(checkpoint_dir, f'BratsCV_epoch_{epoch+1}_{timestamp}.pt')

        # Save model state dictionary and optimizer state
        checkpoint = {
            'epoch': epoch + 1,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,
            'train_loss': train_loss,
            'val_loss': val_loss,
            'train_dice': train_dice,
            'val_dice': val_dice,
            'best_val_dice': best_val_dice,
            'learning_rate': current_lr
        }
        torch.save(checkpoint, checkpoint_path)

        # Upload checkpoint to Hugging Face
        try:
            api.upload_file(
                path_or_fileobj=checkpoint_path,
                path_in_repo=f"checkpoints/BratsCV_epoch_{epoch+1}.pt",
                repo_id=repo_name,
                token=hf_token
            )
            print(f"Checkpoint for epoch {epoch+1} uploaded to Hugging Face!")
        except Exception as e:
            print(f"Error uploading checkpoint to Hugging Face: {e}")

    # Check for early stopping
    early_stopping(val_loss)
    if early_stopping.early_stop:
        print(f"Early stopping triggered after {epoch+1} epochs!")

        # Save final model after early stopping
        final_model_path = os.path.join(checkpoint_dir, 'BratsCV_final.pt')
        torch.save(model, final_model_path)

        # Upload final model to Hugging Face
        api.upload_file(
            path_or_fileobj=final_model_path,
            path_in_repo="BratsCV_final.pt",
            repo_id=repo_name,
            token=hf_token
        )
        print("Final model uploaded to Hugging Face!")
        break

    # Free memory after each epoch